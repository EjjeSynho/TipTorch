{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MHvuWIUHdIpt"
      },
      "source": [
        "# Handwritten Digit Recognition\n",
        "- Author = Amitrajit Bose\n",
        "- Dataset = MNIST\n",
        "- [Medium Article Link](https://medium.com/@amitrajit_bose/handwritten-digit-mnist-pytorch-977b5338e627)\n",
        "- Frameworks = PyTorch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oGjRmijsaXJ3"
      },
      "source": [
        "### Necessary Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "TOyGrPT5ASDc"
      },
      "outputs": [],
      "source": [
        "# Import necessary packages\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uLdtrS4zaeEs"
      },
      "source": [
        "### Download The Dataset & Define The Transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "sZD2NGz2Ak6w"
      },
      "outputs": [],
      "source": [
        "### Run this cell\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.5,), (0.5,)),])\n",
        "\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('C:/Users/akuznets/Data/MNIST_data/', download=False, train=True, transform=transform)\n",
        "valset   = datasets.MNIST('C:/Users/akuznets/Data/MNIST_data/', download=False, train=False, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "valloader   = torch.utils.data.DataLoader(valset,   batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GcAfrn2falkK"
      },
      "source": [
        "### Exploring The Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "colab_type": "code",
        "id": "xOjlOyjcCezX",
        "outputId": "c68b40b1-cf61-461f-c3c8-39f865d35209"
      },
      "outputs": [],
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "print(type(images))\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "colab_type": "code",
        "id": "EuBvOWmGDHOq",
        "outputId": "1ef33d49-4947-47cc-91f1-1895b8544559"
      },
      "outputs": [],
      "source": [
        "plt.imshow(images[0].numpy().squeeze(), cmap='gray_r');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "colab_type": "code",
        "id": "F9CppCcqDLtB",
        "outputId": "d6bd6bd1-3d7b-47ae-f734-4d3bf24c975d"
      },
      "outputs": [],
      "source": [
        "figure = plt.figure()\n",
        "num_of_images = 60\n",
        "for index in range(1, num_of_images + 1):\n",
        "    plt.subplot(6, 10, index)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lGyau0mOaP2m"
      },
      "source": [
        "### Defining The Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n-NR96UtFSkB"
      },
      "source": [
        "![](https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/image/mlp_mnist.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "colab_type": "code",
        "id": "3WJXInzQGcAy",
        "outputId": "662e4399-1448-4688-88b6-c2e60ae456a8"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "# Layer details for the neural network\n",
        "input_size = 784\n",
        "hidden_sizes = [128, 64]\n",
        "output_size = 10\n",
        "\n",
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[1], output_size),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "colab_type": "code",
        "id": "XyXEUFICQeqF",
        "outputId": "687ca786-145f-443a-8e72-33feb1cbc721"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "oxSLypv2LOD-"
      },
      "outputs": [],
      "source": [
        "criterion = nn.NLLLoss()\n",
        "images, labels = next(iter(trainloader))\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "logps = model(images.cuda())\n",
        "loss = criterion(logps, labels.cuda())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "colab_type": "code",
        "id": "Pj4I2lLgLVWw",
        "outputId": "dd42b7e7-0461-4d4d-a541-2c57946447d4"
      },
      "outputs": [],
      "source": [
        "print('Before backward pass: \\n', model[0].weight.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('After backward pass: \\n', model[0].weight.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "F0ZVHVbvI_yt"
      },
      "outputs": [],
      "source": [
        "from torch import optim\n",
        "\n",
        "# Optimizers require the parameters to optimize and a learning rate\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "colab_type": "code",
        "id": "dS9JqXhhLdkr",
        "outputId": "0538fd2f-07a8-4cec-9efc-f6e64f749794"
      },
      "outputs": [],
      "source": [
        "print('Initial weights - ', model[0].weight)\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "images.resize_(64, 784)\n",
        "\n",
        "# Clear the gradients, do this because gradients are accumulated\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# Forward pass, then backward pass, then update weights\n",
        "output = model(images.cuda())\n",
        "loss = criterion(output, labels.cuda())\n",
        "loss.backward()\n",
        "print('Gradient -', model[0].weight.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "colab_type": "code",
        "id": "wy0KOQ95LgYN",
        "outputId": "de026080-d851-4215-fd6a-a36dac6b0ab5"
      },
      "outputs": [],
      "source": [
        "# Take an update step and few the new weights\n",
        "optimizer.step()\n",
        "print('Updated weights - ', model[0].weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wstRGu4FaJBe"
      },
      "source": [
        "### Core Training Of Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
        "time0 = time()\n",
        "epochs = 15\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        # Flatten MNIST images into a 784 long vector\n",
        "        images = images.view(images.shape[0], -1)\n",
        "    \n",
        "        # Training pass\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(images.cuda())\n",
        "        loss = criterion(output, labels.cuda())\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(\"Epoch {} - Training loss: {}\".format(e, running_loss/len(trainloader)))\n",
        "print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "colab_type": "code",
        "id": "XCsoAdjdLjPb",
        "outputId": "14fb7709-94a1-4f79-8de4-ddf6f7e94e46"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
        "time0 = time()\n",
        "epochs = 15\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        # Flatten MNIST images into a 784 long vector\n",
        "        images = images.view(images.shape[0], -1)\n",
        "    \n",
        "        # Training pass\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(images.cuda())\n",
        "        loss = criterion(output, labels.cuda())\n",
        "        \n",
        "        #This is where the model learns by backpropagating\n",
        "        loss.backward()\n",
        "        \n",
        "        #And optimizes its weights here\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(\"Epoch {} - Training loss: {}\".format(e, running_loss/len(trainloader)))\n",
        "print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "75j9X1b6ME5K"
      },
      "outputs": [],
      "source": [
        "def view_classify(img, ps):\n",
        "    ''' Function for viewing an image and it's predicted classes.\n",
        "    '''\n",
        "    ps = ps.cpu().data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    ax2.set_yticklabels(np.arange(10))\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "colab_type": "code",
        "id": "Ie9Fffl_Mqp6",
        "outputId": "f343c543-4b80-4b77-da25-5f9ebb1e2e05"
      },
      "outputs": [],
      "source": [
        "images, labels = next(iter(valloader))\n",
        "\n",
        "img = images[0].view(1, 784)\n",
        "# Turn off gradients to speed up this part\n",
        "with torch.no_grad():\n",
        "    logps = model(img.cuda())\n",
        "\n",
        "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
        "ps = torch.exp(logps)\n",
        "probab = list(ps.cpu().numpy()[0])\n",
        "print(\"Predicted Digit =\", probab.index(max(probab)))\n",
        "view_classify(img.view(1, 28, 28), ps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wAEvDtiaM6RQ"
      },
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "colab_type": "code",
        "id": "5sBPmaBONPkT",
        "outputId": "b2e7b282-8b3b-411f-9d7f-e6f7c2c4faef"
      },
      "outputs": [],
      "source": [
        "correct_count, all_count = 0, 0\n",
        "for images,labels in valloader:\n",
        "  for i in range(len(labels)):\n",
        "    img = images[i].view(1, 784)\n",
        "    # Turn off gradients to speed up this part\n",
        "    with torch.no_grad():\n",
        "        logps = model(img.cuda())\n",
        "\n",
        "    # Output of the network are log-probabilities, need to take exponential for probabilities\n",
        "    ps = torch.exp(logps)\n",
        "    probab = list(ps.cpu().numpy()[0])\n",
        "    pred_label = probab.index(max(probab))\n",
        "    true_label = labels.numpy()[i]\n",
        "    if(true_label == pred_label):\n",
        "      correct_count += 1\n",
        "    all_count += 1\n",
        "\n",
        "print(\"Number Of Images Tested =\", all_count)\n",
        "print(\"\\nModel Accuracy =\", (correct_count/all_count))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "handwritten_digit_recognition_GPU.ipynb",
      "provenance": [],
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('AO-torch')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "f202dae6a8f0c20f6234b5ecf2501042fb88e0c3e3abf17b9a049dc33bf4739f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
